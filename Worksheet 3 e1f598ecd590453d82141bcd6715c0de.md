# Worksheet 3

# What technical debt has been cleaned up

[https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/commit/dc96776844c44c32c8d49fadbe77bfa6650fd088](https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/commit/dc96776844c44c32c8d49fadbe77bfa6650fd088)

In this commit, we payed off prudent and deliberate technical debt. It prudent and deliberate because we chose to not separate out database and logic layers correctly in order to complete the feature for the iteration. It was payed off by correctly refactoring our code so that the logic layer and database layer into their separate levels.

# What technical debt did you leave?

We kept the items in the shop hard coded in rather than putting them into a database. This is because the values will never change, and we found that the time cost of making these values store in the database would outweigh the immediate benefits gained. This is deliberate prudent technical debt.

# Discuss a Feature or User Story that was cut/re-prioritized

Go for walks with your pet:

[https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/issues/4](https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/issues/4)

Early on we wanted to include multiple ‘mini-games’ in the app, we planned to add at least one other game where you would “walk” your pet. You will probably notice there is only one minigame in the minigames list. We (unofficially) determined early in iteration 2 that implementing further mini games would take too much time, time that we needed to spend developing the ‘backbones’ of the app.

# Acceptance test/end-to-end

The very first test I wrote was testing the create a pet feature that is seen by first time users. Most tests were fairly similar, as each action was defined as a ViewInteraction. For this test I physically had to set the rule to start on the CreatePet activity instead of how the app is usually ran, since we usually started the application up from a different activity that checks if the user has ever played or not (to determine if they need to create a pet). From there I simply had the user click an option (I believe I chose dog) of what kind of pet they want, then the name that is given is "espresso". After that the tutorial screen is prompt, which is then passed on by clicking the finish button. After that, the test is complete.

Link to this test below:

[https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/blob/master/app/src/androidTest/java/com/example/minipets/objects/IndividualTests/TestPetCreation.java](https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/blob/master/app/src/androidTest/java/com/example/minipets/objects/IndividualTests/TestPetCreation.java)

# Acceptance test, untestable

The first challenge was figuring out how the @Rules worked. Since our app starts on different screens based (not MainActivity) off of some simple logic, I had to figure out how to start the tests from different starting points. I also found that changing which database I was using to be a little difficult, which if I am going to be completely honest still might not be working properly. What this means is the systems test COULD mess with the test phones data if the systems test is ran on a users phone. I didn't think that was too much of an issue since in the real world a user would never run these tests, so I didn't sweat it too much. What was damn near impossible to test was the only feature I didn't actually write a test for (I know only 6 tests are there but some cover multiple features), and that was fetch. Sure a stub could have been used (maybe?) for this, but the amount of random values and tough workarounds that were implemented made creating a systems test for fetch impossible in my eyes. Re-creating the same game over and over again also wouldn't exactly test the true functionality of the game.

# Velocity/teamwork

Velocity Chart Description
The trend here shows that we went quite over what we estimated for the last two iterations mainly because we had features that had to be reworked over the last two iterations and our previous time estimates didn’t put that into account, In the last iteration we spent time refactoring our code and adding a functioning logic layer which added a lot of extra time to some of the previously completed features.

Tasks evidence links for the velocity:
[https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/issues/40](https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/issues/40)

[https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/issues/24](https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/issues/24)

[https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/issues/40](https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/issues/40)

[https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/issues/50](https://code.cs.umanitoba.ca/3350-winter-2021-a03/minipets-comp3350-a03-group12/-/issues/50)